{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train_data'\n",
    "df_train = pd.read_csv('./df_train.csv')\n",
    "\n",
    "val_path = './validation_data'\n",
    "df_val = pd.read_csv('./df_validation.csv')\n",
    "\n",
    "small_path = './small_sample'\n",
    "df_small = pd.read_csv('./df_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batch_images(images, df, path):\n",
    "    features_target = []\n",
    "    for im in images:\n",
    "        current_image = np.array(imageio.imread(os.path.join(path, im)))/255\n",
    "        image_id = int(im.split('.')[0])\n",
    "        target = int(df[df.id == image_id]['broken'])\n",
    "        features_target.append((current_image, target))\n",
    "    return features_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(df, path, batch_size):\n",
    "    images_name = [f for f in os.listdir(path) if f.split('.')[1] == 'png']\n",
    "    random.shuffle(images_name)\n",
    "    n = len(df)\n",
    "    for i in range(0, n, batch_size):\n",
    "        images_filter = images_name[i:(i+batch_size)]\n",
    "        data = read_batch_images(images_filter, df, path)\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 8, 3)\n",
    "        self.fc1 = nn.Linear(12800,5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drp1 = nn.Dropout(0.25)\n",
    "        self.drp2 = nn.Dropout(0.25)\n",
    "        self.drp3 = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        fo = self.pool(self.relu(self.conv1(x)))\n",
    "        so = self.pool(self.relu(self.conv2(fo)))\n",
    "        to = self.pool(self.relu(self.conv3(so))).view(-1,12800)\n",
    "        fc1_out = self.drp1(self.relu(self.fc1(to)))\n",
    "        fc2_out = self.drp2(self.relu(self.fc2(fc1_out)))\n",
    "        fc3_out = self.drp3(self.relu(self.fc3(fc2_out)))\n",
    "        out = self.fc4(fc3_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(target, score):\n",
    "    fpr, tpr, threshold = roc_curve(target, score)\n",
    "    tnr = [1-f for f in fpr]\n",
    "    auc_roc = roc_auc_score(target, score)\n",
    "    df = pd.DataFrame({'sens' : tpr, 'spec': tnr, 'threshold': threshold})\n",
    "    good_metrics = df[df.sens >= 0.85] \n",
    "    index_best = np.argmax(good_metrics.spec)\n",
    "    df_best = good_metrics.iloc[index_best]\n",
    "    best_sens = df_best.sens\n",
    "    best_spec = df_best.spec\n",
    "    best_th = df_best.threshold\n",
    "\n",
    "    return  auc_roc, best_sens, best_spec, best_th\n",
    "    \n",
    "def train(model, optimizer, criterion, df_train, train_path, df_val, val_path, num_epochs, batch_size, device):\n",
    "    for i in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        val_losses = []\n",
    "        tr_losses = []\n",
    "        model.train()\n",
    "        for batch in batch_generator(df_train, train_path, batch_size):\n",
    "            x = [d[0] for d in batch]\n",
    "            y = [d[1] for d in batch]\n",
    "            n_batch_size = len(x) if len(x) < batch_size else batch_size\n",
    "            x_t = torch.tensor(x, dtype=torch.float, device=device).view(n_batch_size, 1, 340, 340)\n",
    "            y_t = torch.tensor(y, dtype=torch.float, device=device)\n",
    "            model.zero_grad()\n",
    "            output = model(x_t)\n",
    "            loss = criterion(output.view(-1), y_t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        val_probs, ys, val_loss = validate(model, criterion, df_val, val_path, batch_size, device)\n",
    "        val_losses += [val_loss / df_val.shape[0]]\n",
    "        tr_losses += [total_loss / df_train.shape[0]]\n",
    "        auc_roc, sens, spec, th = get_performance_metrics(ys, val_probs)\n",
    "        \n",
    "        print('Epoch {}, avg train loss per image {}, avg valid loss per image {}, auc {}, sens {}, spec {}, th {}'.format(\n",
    "            i+1, tr_losses[-1], val_losses[-1], auc_roc, sens, spec, th\n",
    "        ))\n",
    "    return tr_losses[-1], val_losses[-1]\n",
    "\n",
    "def validate(model, criterion, df_val, val_path, batch_size, device):\n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "    probs = []\n",
    "    ys = []\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    with torch.no_grad():\n",
    "        for batch in batch_generator(df_val, val_path, batch_size):\n",
    "            x = [d[0] for d in batch]\n",
    "            y = [d[1] for d in batch]\n",
    "            n_batch_size = len(x) if len(x) < batch_size else batch_size\n",
    "            x_t = torch.tensor(x, dtype=torch.float, device=device).view(n_batch_size, 1, 340, 340)\n",
    "            y_t = torch.tensor(y, dtype=torch.float, device=device)\n",
    "            output = model(x_t)\n",
    "            probs += list(sigmoid(output).view(-1).detach().cpu().numpy())\n",
    "            ys += y\n",
    "            loss = criterion(output.view(-1), y_t)\n",
    "            val_total_loss += loss.item()\n",
    "    return probs, ys, val_total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda')\n",
    "model = BasicNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, avg train loss per image 0.4202332911591013, avg valid loss per image 0.39311170857042327, auc 0.7751813282547915, sens 0.8521739130434782, spec 0.565703634669152, th 0.20895293354988098\n",
      "Epoch 2, avg train loss per image 0.34909010427644094, avg valid loss per image 0.3600966519606818, auc 0.8303213258235747, sens 0.8521739130434782, spec 0.6328052190121156, th 0.16947956383228302\n",
      "Epoch 3, avg train loss per image 0.2671518438759358, avg valid loss per image 0.3547662418801695, auc 0.8570768669719194, sens 0.8521739130434782, spec 0.6971109040074557, th 0.2188863605260849\n",
      "Epoch 4, avg train loss per image 0.1992910206759127, avg valid loss per image 0.34812374050490963, auc 0.8708172940556749, sens 0.8521739130434782, spec 0.7232059645852749, th 0.2037641853094101\n",
      "Epoch 5, avg train loss per image 0.15192575010741144, avg valid loss per image 0.4782202138021554, auc 0.8677823250536895, sens 0.8521739130434782, spec 0.7129543336439887, th 0.01191153097897768\n",
      "Epoch 6, avg train loss per image 0.10886541650687066, avg valid loss per image 0.49547025127549377, auc 0.8552777665221444, sens 0.8521739130434782, spec 0.6700838769804287, th 0.008931693620979786\n",
      "Epoch 7, avg train loss per image 0.08498162563585651, avg valid loss per image 0.49615111610839996, auc 0.8759755257506383, sens 0.8521739130434782, spec 0.7260018639328985, th 0.014908582903444767\n",
      "Epoch 8, avg train loss per image 0.05192654901359559, avg valid loss per image 0.5815501039932073, auc 0.8853478666072369, sens 0.8521739130434782, spec 0.7698042870456664, th 0.005421993788331747\n",
      "Epoch 9, avg train loss per image 0.03637845969882563, avg valid loss per image 0.543818615554208, auc 0.886672879776328, sens 0.8608695652173913, spec 0.7726001863932899, th 0.01318094041198492\n",
      "Epoch 10, avg train loss per image 0.025397158982693353, avg valid loss per image 0.680584493449854, auc 0.8788524656590625, sens 0.8521739130434782, spec 0.7530288909599254, th 0.0030085935723036528\n",
      "Epoch 11, avg train loss per image 0.022029509060397353, avg valid loss per image 0.6362352807071926, auc 0.8718384051217635, sens 0.8521739130434782, spec 0.6859273066169618, th 0.001814413582906127\n",
      "Epoch 12, avg train loss per image 0.028012040880562188, avg valid loss per image 0.620166208041819, auc 0.879533206369788, sens 0.8521739130434782, spec 0.7148182665424045, th 0.0013717636466026306\n",
      "Epoch 13, avg train loss per image 0.02410804689712461, avg valid loss per image 0.5789953629048119, auc 0.8850237043640342, sens 0.8565217391304348, spec 0.7623485554520038, th 0.002429293468594551\n",
      "Epoch 14, avg train loss per image 0.01749673516028883, avg valid loss per image 0.9799166885779989, auc 0.870821346083715, sens 0.8521739130434782, spec 0.7148182665424045, th 3.8149279134813696e-05\n",
      "Epoch 15, avg train loss per image 0.02605895356856241, avg valid loss per image 0.5483836008589436, auc 0.8781271526398963, sens 0.8565217391304348, spec 0.7381174277726001, th 0.009911250323057175\n",
      "Epoch 16, avg train loss per image 0.01786383396556298, avg valid loss per image 0.5961237171163077, auc 0.8737671704688197, sens 0.8521739130434782, spec 0.7110904007455732, th 0.0027115170378237963\n",
      "Epoch 17, avg train loss per image 0.012211883427438267, avg valid loss per image 0.720816991737231, auc 0.8887069978524251, sens 0.8521739130434782, spec 0.7744641192917054, th 0.0015436596004292369\n",
      "Epoch 18, avg train loss per image 0.009050013604101273, avg valid loss per image 0.9435214718213378, auc 0.8812431622026824, sens 0.8521739130434782, spec 0.7166821994408201, th 4.43992976215668e-05\n",
      "Epoch 19, avg train loss per image 0.01622385987290369, avg valid loss per image 0.8076306139465624, auc 0.8718100409254832, sens 0.8521739130434782, spec 0.6831314072693383, th 0.0006426998879760504\n",
      "Epoch 20, avg train loss per image 0.01853750235652194, avg valid loss per image 0.6103123945676516, auc 0.879873576725151, sens 0.8521739130434782, spec 0.7595526561043803, th 0.0054249027743935585\n",
      "Epoch 21, avg train loss per image 0.010770973513678983, avg valid loss per image 0.6632936318183041, auc 0.8780015397706553, sens 0.8521739130434782, spec 0.6887232059645852, th 0.0011639312142506242\n",
      "Epoch 22, avg train loss per image 0.017383565135921552, avg valid loss per image 0.6664593054908785, auc 0.877260018639329, sens 0.8521739130434782, spec 0.739049394221808, th 0.0015135550638660789\n",
      "Epoch 23, avg train loss per image 0.013159913642245858, avg valid loss per image 0.7498063784970381, auc 0.8692694193443818, sens 0.8521739130434782, spec 0.7176141658900279, th 0.0015047688502818346\n",
      "Epoch 24, avg train loss per image 0.01797152995933929, avg valid loss per image 0.6665693704181451, auc 0.8780015397706553, sens 0.8565217391304348, spec 0.7455731593662629, th 0.005788788665086031\n",
      "Epoch 25, avg train loss per image 0.011196889887455264, avg valid loss per image 0.9010375023848811, auc 0.8824060942501721, sens 0.8521739130434782, spec 0.7809878844361603, th 0.00125401490367949\n",
      "Epoch 26, avg train loss per image 0.01707026029753585, avg valid loss per image 0.7745149415543879, auc 0.8720977349163257, sens 0.8521739130434782, spec 0.7381174277726001, th 0.00042395241325721145\n",
      "Epoch 27, avg train loss per image 0.011837358016574054, avg valid loss per image 0.7302546630615651, auc 0.8547226386806597, sens 0.8521739130434782, spec 0.6868592730661696, th 0.0007826302899047732\n",
      "Epoch 28, avg train loss per image 0.016490404438187584, avg valid loss per image 0.856440873020107, auc 0.8765306535921228, sens 0.8521739130434782, spec 0.761416589002796, th 0.00026973080821335316\n",
      "Epoch 29, avg train loss per image 0.012851693196371406, avg valid loss per image 0.8584573076764895, auc 0.865841403622513, sens 0.8521739130434782, spec 0.6989748369058714, th 0.0003005472826771438\n",
      "Epoch 30, avg train loss per image 0.011384459339964079, avg valid loss per image 1.0011287200295367, auc 0.8669597633615626, sens 0.8521739130434782, spec 0.7455731593662629, th 0.0006132459384389222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.011384459339964079, 1.0011287200295367)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model=model, optimizer=optimizer, criterion=criterion, \n",
    "      df_train=df_train, train_path='./train_data', df_val=df_val, val_path='./validation_data', \n",
    "      num_epochs=epochs, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
