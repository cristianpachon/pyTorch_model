{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train_data'\n",
    "df_train = pd.read_csv('./df_train.csv')\n",
    "\n",
    "val_path = './validation_data'\n",
    "df_val = pd.read_csv('./df_validation.csv')\n",
    "\n",
    "small_path = './small_sample'\n",
    "df_small = pd.read_csv('./df_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batch_images(images, df, path):\n",
    "    features_target = []\n",
    "    for im in images:\n",
    "        current_image = np.array(imageio.imread(os.path.join(path, im)))/255\n",
    "        image_id = int(im.split('.')[0])\n",
    "        target = int(df[df.id == image_id]['broken'])\n",
    "        features_target.append((current_image, target))\n",
    "    return features_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(df, path, batch_size):\n",
    "    images_name = [f for f in os.listdir(path) if f.split('.')[1] == 'png']\n",
    "    random.shuffle(images_name)\n",
    "    n = len(df)\n",
    "    for i in range(0, n, batch_size):\n",
    "        images_filter = images_name[i:(i+batch_size)]\n",
    "        data = read_batch_images(images_filter, df, path)\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 8, 3)\n",
    "        self.fc1 = nn.Linear(12800,5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drp1 = nn.Dropout(0.25)\n",
    "        self.drp2 = nn.Dropout(0.25)\n",
    "        self.drp3 = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        fo = self.pool(self.relu(self.conv1(x)))\n",
    "        so = self.pool(self.relu(self.conv2(fo)))\n",
    "        to = self.pool(self.relu(self.conv3(so))).view(-1,12800)\n",
    "        fc1_out = self.drp1(self.relu(self.fc1(to)))\n",
    "        fc2_out = self.drp2(self.relu(self.fc2(fc1_out)))\n",
    "        fc3_out = self.drp3(self.relu(self.fc3(fc2_out)))\n",
    "        out = self.fc4(fc3_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(target, score):\n",
    "    fpr, tpr, threshold = roc_curve(target, score)\n",
    "    tnr = [1-f for f in fpr]\n",
    "    auc_roc = roc_auc_score(target, score)\n",
    "    df = pd.DataFrame({'sens' : tpr, 'spec': tnr, 'threshold': threshold})\n",
    "    good_metrics = df[df.sens >= 0.85] \n",
    "    index_best = np.argmax(good_metrics.spec)\n",
    "    df_best = good_metrics.iloc[index_best]\n",
    "    best_sens = df_best.sens\n",
    "    best_spec = df_best.spec\n",
    "    best_th = df_best.threshold\n",
    "\n",
    "    return  auc_roc, best_sens, best_spec, best_th\n",
    "    \n",
    "def train(model, optimizer, criterion, df_train, train_path, df_val, val_path, num_epochs, batch_size, device):\n",
    "    for i in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        val_losses = []\n",
    "        tr_losses = []\n",
    "        model.train()\n",
    "        for batch in batch_generator(df_train, train_path, batch_size):\n",
    "            x = [d[0] for d in batch]\n",
    "            y = [d[1] for d in batch]\n",
    "            n_batch_size = len(x) if len(x) < batch_size else batch_size\n",
    "            x_t = torch.tensor(x, dtype=torch.float, device=device).view(n_batch_size, 1, 340, 340)\n",
    "            y_t = torch.tensor(y, dtype=torch.float, device=device)\n",
    "            model.zero_grad()\n",
    "            output = model(x_t)\n",
    "            loss = criterion(output.view(-1), y_t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        val_probs, ys, val_loss = validate(model, criterion, df_val, val_path, batch_size, device)\n",
    "        val_losses += [val_loss / df_val.shape[0]]\n",
    "        tr_losses += [total_loss / df_train.shape[0]]\n",
    "        auc_roc, sens, spec, th = get_performance_metrics(ys, val_probs)\n",
    "        \n",
    "        print('Epoch {}, avg train loss per image {}, avg valid loss per image {}, auc {}, sens {}, spec {}, th {}'.format(\n",
    "            i+1, tr_losses[-1], val_losses[-1], auc_roc, sens, spec, th\n",
    "        ))\n",
    "    return tr_losses[-1], val_losses[-1]\n",
    "\n",
    "def validate(model, criterion, df_val, val_path, batch_size, device):\n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "    probs = []\n",
    "    ys = []\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    with torch.no_grad():\n",
    "        for batch in batch_generator(df_val, val_path, batch_size):\n",
    "            x = [d[0] for d in batch]\n",
    "            y = [d[1] for d in batch]\n",
    "            n_batch_size = len(x) if len(x) < batch_size else batch_size\n",
    "            x_t = torch.tensor(x, dtype=torch.float, device=device).view(n_batch_size, 1, 340, 340)\n",
    "            y_t = torch.tensor(y, dtype=torch.float, device=device)\n",
    "            output = model(x_t)\n",
    "            probs += list(sigmoid(output).view(-1).detach().cpu().numpy())\n",
    "            ys += y\n",
    "            loss = criterion(output.view(-1), y_t)\n",
    "            val_total_loss += loss.item()\n",
    "    return probs, ys, val_total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda')\n",
    "model = BasicNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, avg train loss per image 0.4384501655353961, avg valid loss per image 0.39715766977641737, auc 0.762737550143847, sens 0.8521739130434782, spec 0.5647716682199441, th 0.1460203230381012\n"
     ]
    }
   ],
   "source": [
    "train(model=model, optimizer=optimizer, criterion=criterion, \n",
    "      df_train=df_train, train_path='./train_data', df_val=df_val, val_path='./validation_data', \n",
    "      num_epochs=epochs, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
